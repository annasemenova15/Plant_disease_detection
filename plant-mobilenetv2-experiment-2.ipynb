{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Final project\n#### Plant disease detection --> multiclassification problem\nChanged learning rate to 0.00001, dropout to 0.4, epochs to 7","metadata":{}},{"cell_type":"markdown","source":"1. Install the packages","metadata":{}},{"cell_type":"code","source":"# Dowload the packages\n!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:34.228684Z","iopub.execute_input":"2023-04-11T12:45:34.228965Z","iopub.status.idle":"2023-04-11T12:45:46.578852Z","shell.execute_reply.started":"2023-04-11T12:45:34.228937Z","shell.execute_reply":"2023-04-11T12:45:46.577674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dowload the packages\nimport numpy as np\nimport pandas as pd\nimport os,os.path\nimport splitfolders\nimport shutil\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib\n\nimport keras.backend as K\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2, MobileNet, VGG16\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\nmatplotlib.style.use('ggplot')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:46.582507Z","iopub.execute_input":"2023-04-11T12:45:46.582837Z","iopub.status.idle":"2023-04-11T12:45:54.409308Z","shell.execute_reply.started":"2023-04-11T12:45:46.582804Z","shell.execute_reply":"2023-04-11T12:45:54.408142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set some default variables\nDATA_DIR = '/kaggle/input/plantvillage-dataset/color'\nBATCH_SIZE = 40\nEPOCHS = 7\nIMAGE_SHAPE = (224, 224)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:54.411009Z","iopub.execute_input":"2023-04-11T12:45:54.411833Z","iopub.status.idle":"2023-04-11T12:45:54.418497Z","shell.execute_reply.started":"2023-04-11T12:45:54.411794Z","shell.execute_reply":"2023-04-11T12:45:54.417576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Upload and explore the data","metadata":{}},{"cell_type":"code","source":"# Check the content\n\npairs = list()\nnumber = list()\n\nfor directory in os.listdir(path=DATA_DIR):\n    columns = directory.split('___')\n    columns.append(directory)\n    \n    sub_path = DATA_DIR + '/' + directory\n    columns.append(len([name for name in os.listdir(path=sub_path)]))\n    \n    pairs.append(columns)\n    \npairs = pd.DataFrame(pairs, columns=['Plant', 'Disease', 'Directory', 'Files'])\npairs.sort_values(by='Plant')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:54.421641Z","iopub.execute_input":"2023-04-11T12:45:54.422233Z","iopub.status.idle":"2023-04-11T12:45:59.436431Z","shell.execute_reply.started":"2023-04-11T12:45:54.422201Z","shell.execute_reply":"2023-04-11T12:45:59.435369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some pairs when only a healthy plant is present. These are Blueberry (17), Orange (3), Raspberry (33), Soybean (4), Squash (5). These are not exactly interesting for us, because we want to detect diseases. Therefore, we will delete these observations in the future. ","metadata":{}},{"cell_type":"code","source":"# Save the directories to be deleted\nrows_to_drop = [17, 3, 33, 4, 5]\ndir_to_delete = pairs[pairs.index.isin(rows_to_drop)]['Directory']\nprint(dir_to_delete.values)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:59.437958Z","iopub.execute_input":"2023-04-11T12:45:59.438942Z","iopub.status.idle":"2023-04-11T12:45:59.448406Z","shell.execute_reply.started":"2023-04-11T12:45:59.438903Z","shell.execute_reply":"2023-04-11T12:45:59.447130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a directory images\nos.mkdir('images')\n\n# Make subdirectories train, val, test\nos.mkdir(os.path.join('images', 'train'))\nos.mkdir(os.path.join('images', 'val'))\nos.mkdir(os.path.join('images', 'test'))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:59.450049Z","iopub.execute_input":"2023-04-11T12:45:59.450730Z","iopub.status.idle":"2023-04-11T12:45:59.462779Z","shell.execute_reply.started":"2023-04-11T12:45:59.450692Z","shell.execute_reply":"2023-04-11T12:45:59.461749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into folders\nsplitfolders.ratio(DATA_DIR,output = \"images\",seed = 42,ratio = (0.80,0.10,0.10))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:45:59.465118Z","iopub.execute_input":"2023-04-11T12:45:59.466033Z","iopub.status.idle":"2023-04-11T12:52:30.560005Z","shell.execute_reply.started":"2023-04-11T12:45:59.465994Z","shell.execute_reply":"2023-04-11T12:52:30.558792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the directories we saved before\n\nTRAIN_PATH = \"./images/train\"\nVAL_PATH = \"./images/val\"\nTEST_PATH  = \"./images/test\"\nPATHS = [TRAIN_PATH, VAL_PATH, TEST_PATH]\n\nfor sub_directory in dir_to_delete.values:\n    for directory in PATHS:\n        d = directory + '/' + sub_directory\n        shutil.rmtree(d)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:30.561599Z","iopub.execute_input":"2023-04-11T12:52:30.562099Z","iopub.status.idle":"2023-04-11T12:52:31.015564Z","shell.execute_reply.started":"2023-04-11T12:52:30.562057Z","shell.execute_reply":"2023-04-11T12:52:31.014508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate batches of tensor image data with real-time data augmentation\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\ntrain_gen = datagen.flow_from_directory(directory = TRAIN_PATH, \n                                          class_mode=\"categorical\",\n                                          target_size = IMAGE_SHAPE,\n                                          batch_size = BATCH_SIZE,\n                                          color_mode='rgb',\n                                          seed = 1234,\n                                          shuffle = True)\n\nval_gen = datagen.flow_from_directory(directory = VAL_PATH, \n                                          class_mode=\"categorical\",\n                                          target_size = IMAGE_SHAPE,\n                                          batch_size = BATCH_SIZE,\n                                          color_mode='rgb',\n                                          seed = 1234,\n                                          shuffle = True)\n\ntest_gen = datagen.flow_from_directory(directory = TEST_PATH, \n                                          class_mode=\"categorical\",\n                                          target_size = IMAGE_SHAPE,\n                                          batch_size = BATCH_SIZE,\n                                          color_mode='rgb',\n                                          shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:31.017095Z","iopub.execute_input":"2023-04-11T12:52:31.017454Z","iopub.status.idle":"2023-04-11T12:52:32.957901Z","shell.execute_reply.started":"2023-04-11T12:52:31.017419Z","shell.execute_reply":"2023-04-11T12:52:32.956895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Make a model","metadata":{}},{"cell_type":"code","source":"# The function for computing f1 score (macro) for multiclass classification in Keras\ndef f1_macro(y_true, y_pred):    \n    def recall_m(y_true, y_pred):\n        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        \n        recall = TP / (Positives+K.epsilon())    \n        return recall \n    \n    \n    def precision_m(y_true, y_pred):\n        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    \n        precision = TP / (Pred_Positives+K.epsilon())\n        return precision \n    \n    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n    \n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:32.961941Z","iopub.execute_input":"2023-04-11T12:52:32.962240Z","iopub.status.idle":"2023-04-11T12:52:32.970318Z","shell.execute_reply.started":"2023-04-11T12:52:32.962211Z","shell.execute_reply":"2023-04-11T12:52:32.969015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a directory for models\nos.mkdir('models')\n\n# Make subdirectories train, val, test\nos.mkdir(os.path.join('models', 'first_version'))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:32.972105Z","iopub.execute_input":"2023-04-11T12:52:32.972832Z","iopub.status.idle":"2023-04-11T12:52:32.984911Z","shell.execute_reply.started":"2023-04-11T12:52:32.972795Z","shell.execute_reply":"2023-04-11T12:52:32.983839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we create checkpoint for the first model\nCHECKPOINT_PATH_MODEL_FIRST = \"./models/first_version\"\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH_MODEL_FIRST,\n                                      monitor='val_loss',\n                                      save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:32.987304Z","iopub.execute_input":"2023-04-11T12:52:32.988826Z","iopub.status.idle":"2023-04-11T12:52:32.996077Z","shell.execute_reply.started":"2023-04-11T12:52:32.988795Z","shell.execute_reply":"2023-04-11T12:52:32.995047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set early stopping for 2 epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 2, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:32.998007Z","iopub.execute_input":"2023-04-11T12:52:32.998795Z","iopub.status.idle":"2023-04-11T12:52:33.006499Z","shell.execute_reply.started":"2023-04-11T12:52:32.998752Z","shell.execute_reply":"2023-04-11T12:52:33.005501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here MobileNet pretrained model is downloaded; We do not include the last dense layers by setting include_top parameter to False \nfirst_base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='max')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:33.009753Z","iopub.execute_input":"2023-04-11T12:52:33.010094Z","iopub.status.idle":"2023-04-11T12:52:37.265888Z","shell.execute_reply.started":"2023-04-11T12:52:33.010066Z","shell.execute_reply":"2023-04-11T12:52:37.264795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We fix the parameters of the pretrained model\nfirst_base_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:37.267658Z","iopub.execute_input":"2023-04-11T12:52:37.268040Z","iopub.status.idle":"2023-04-11T12:52:37.278927Z","shell.execute_reply.started":"2023-04-11T12:52:37.268001Z","shell.execute_reply":"2023-04-11T12:52:37.277656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we add final layers to the first model\ninputs = first_base_model.input\n\nx = BatchNormalization()(first_base_model.output)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.4, seed=1234)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.4, seed=1235)(x)\nx = Flatten()(x)\n\noutputs = Dense(33, activation='softmax')(x)\n\nfirst_model = Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:37.281938Z","iopub.execute_input":"2023-04-11T12:52:37.282960Z","iopub.status.idle":"2023-04-11T12:52:37.365024Z","shell.execute_reply.started":"2023-04-11T12:52:37.282921Z","shell.execute_reply":"2023-04-11T12:52:37.363957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we check if everything is okay with the model\nfirst_model.compile(\n    optimizer=Adam(0.00001),\n    loss='categorical_crossentropy',\n    metrics=[f1_macro]\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:37.366396Z","iopub.execute_input":"2023-04-11T12:52:37.367044Z","iopub.status.idle":"2023-04-11T12:52:37.388884Z","shell.execute_reply.started":"2023-04-11T12:52:37.367003Z","shell.execute_reply":"2023-04-11T12:52:37.387792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we fit the model\nhistory = first_model.fit(train_gen, epochs=EPOCHS, validation_data=val_gen, callbacks=[checkpoint_callback, early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:52:37.390706Z","iopub.execute_input":"2023-04-11T12:52:37.391123Z","iopub.status.idle":"2023-04-11T13:04:59.673072Z","shell.execute_reply.started":"2023-04-11T12:52:37.391076Z","shell.execute_reply":"2023-04-11T13:04:59.672035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = first_model.evaluate(test_gen, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:04:59.675251Z","iopub.execute_input":"2023-04-11T13:04:59.675574Z","iopub.status.idle":"2023-04-11T13:05:10.065486Z","shell.execute_reply.started":"2023-04-11T13:04:59.675544Z","shell.execute_reply":"2023-04-11T13:05:10.064497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we make the first plot for Loss\nEpochs = [i+1 for i in range(len(history.history['f1_macro']))]\n\nplt.plot(Epochs, history.history['loss'], label = 'training loss')\nplt.plot(Epochs, history.history['val_loss'], label = 'validation loss')\nplt.grid(True)\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:05:10.068949Z","iopub.execute_input":"2023-04-11T13:05:10.070726Z","iopub.status.idle":"2023-04-11T13:05:10.309739Z","shell.execute_reply.started":"2023-04-11T13:05:10.070683Z","shell.execute_reply":"2023-04-11T13:05:10.308739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we make the first plot for F1-score\nEpochs = [i+1 for i in range(len(history.history['f1_macro']))]\n\nplt.plot(Epochs, history.history['f1_macro'], label = 'training f1 score')\nplt.plot(Epochs, history.history['val_f1_macro'], label = 'validation f1 score')\nplt.grid(True)\nplt.legend()\nplt.title('Training and Validation F1-score')\nplt.xlabel('Epochs')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:05:10.311289Z","iopub.execute_input":"2023-04-11T13:05:10.311675Z","iopub.status.idle":"2023-04-11T13:05:10.550406Z","shell.execute_reply.started":"2023-04-11T13:05:10.311637Z","shell.execute_reply":"2023-04-11T13:05:10.549410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}